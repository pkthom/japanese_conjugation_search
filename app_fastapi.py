import os
import re
import time
import logging
import threading
import pandas as pd
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request as StarletteRequest
from jinja2 import Environment, FileSystemLoader
from threading import Lock
import asyncio

VERB_CSV_PATH = os.environ.get("VERB_CSV_PATH", "/app/verb.csv")
ADJECTIVE_CSV_PATH = os.environ.get("ADJECTIVE_CSV_PATH", "/app/adjective.csv")

app = FastAPI(title="Japanese Verb and Adjective Conjugation")

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²ã™ã‚‹ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ï¼ˆ502ã‚¨ãƒ©ãƒ¼å®Œå…¨é˜²æ­¢ã®ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å®Œå…¨ã«ç„¡åŠ¹åŒ–ï¼‰
class TimingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: StarletteRequest, call_next):
        start_time = time.time()
        request_id = f"{request.client.host if request.client else 'unknown'}:{request.client.port if request.client else 'unknown'}-{int(start_time * 1000)}"
        is_head = request.method == "HEAD"
        
        # HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å ´åˆã¯ã€å³åº§ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆ502ã‚¨ãƒ©ãƒ¼å®Œå…¨é˜²æ­¢ï¼‰
        if is_head:
            logger.info(f"ğŸ“¥ Middleware: HEAD Request {request_id} started: {request.url.path}")
            try:
                # å³åº§ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆå‡¦ç†ã¯ä¸è¦ï¼‰
                response = HTMLResponse(content="", status_code=200)
                response.headers["X-Process-Time"] = "0.000"
                response.headers["X-Request-ID"] = request_id
                response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
                response.headers["Pragma"] = "no-cache"
                response.headers["Expires"] = "0"
                response.headers["CF-Cache-Status"] = "DYNAMIC"
                response.headers["Connection"] = "keep-alive"
                process_time = time.time() - start_time
                logger.info(f"â±ï¸ Middleware: HEAD Request {request_id} completed in {process_time:.3f}s, status: 200")
                return response
            except Exception as e:
                logger.error(f"âŒ Middleware: HEAD Request {request_id} failed: {e}", exc_info=True)
                # ã‚¨ãƒ©ãƒ¼ã§ã‚‚200ã‚’è¿”ã™ï¼ˆ502ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
                response = HTMLResponse(content="", status_code=200)
                response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
                response.headers["CF-Cache-Status"] = "DYNAMIC"
                response.headers["Connection"] = "keep-alive"
                return response
        
        logger.info(f"ğŸ“¥ Middleware: Request {request_id} started: {request.method} {request.url.path}")
        try:
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç¢ºå®Ÿã«å‡¦ç†ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—ï¼‰
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã€å¿…ãšãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆ502ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
            try:
                response = await call_next(request)
            except Exception as inner_error:
                # å†…éƒ¨ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã§ã‚‚ã€é©åˆ‡ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
                logger.error(f"âŒ Inner error in request {request_id}: {inner_error}", exc_info=True)
                try:
                    response = HTMLResponse(content=render_template("error.html", error_message=f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(inner_error)}"), status_code=500)
                except:
                    response = HTMLResponse(content=f"<h1>ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ</h1><p>{str(inner_error)}</p><p><a href='/'>ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã«æˆ»ã‚‹</a></p>", status_code=500)
            
            process_time = time.time() - start_time
            logger.info(f"â±ï¸ Middleware: Request {request_id} completed in {process_time:.3f}s, status: {response.status_code}")
            if process_time > 1.0:
                logger.warning(f"âš ï¸ Slow request {request_id}: {request.method} {request.url.path} took {process_time:.3f}s")
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ã«å‡¦ç†æ™‚é–“ã‚’è¿½åŠ ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            response.headers["X-Process-Time"] = f"{process_time:.3f}"
            response.headers["X-Request-ID"] = request_id
            # Cloudflareç”¨ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆé˜²æ­¢ï¼‰
            response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            response.headers["Pragma"] = "no-cache"
            response.headers["Expires"] = "0"
            # Cloudflareã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ãªã„ã‚ˆã†ã«æŒ‡ç¤º
            response.headers["CF-Cache-Status"] = "DYNAMIC"
            # æ¥ç¶šã‚’ä¿æŒ
            response.headers["Connection"] = "keep-alive"
            # Content-Lengthã¨Transfer-Encodingã®ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚ã€Content-Lengthã‚’å‰Šé™¤
            # UvicornãŒè‡ªå‹•çš„ã«Transfer-Encoding: chunkedã‚’è¨­å®šã™ã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚
            if "Content-Length" in response.headers:
                del response.headers["Content-Length"]
            return response
        except Exception as e:
            process_time = time.time() - start_time
            logger.error(f"âŒ Middleware: Request {request_id} failed after {process_time:.3f}s: {e}", exc_info=True)
            # ã‚¨ãƒ©ãƒ¼ã§ã‚‚502ã‚¨ãƒ©ãƒ¼ã§ã¯ãªãã€é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã‚’è¿”ã™
            try:
                error_response = HTMLResponse(content=render_template("error.html", error_message=f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"), status_code=500)
                error_response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
                error_response.headers["CF-Cache-Status"] = "DYNAMIC"
                error_response.headers["Connection"] = "keep-alive"
                # Content-Lengthã¨Transfer-Encodingã®ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚ã€Content-Lengthã‚’å‰Šé™¤
                if "Content-Length" in error_response.headers:
                    del error_response.headers["Content-Length"]
                return error_response
            except:
                error_response = HTMLResponse(content=f"<h1>ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ</h1><p>{str(e)}</p><p><a href='/'>ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã«æˆ»ã‚‹</a></p>", status_code=500)
                error_response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
                error_response.headers["CF-Cache-Status"] = "DYNAMIC"
                error_response.headers["Connection"] = "keep-alive"
                # Content-Lengthã¨Transfer-Encodingã®ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚ã€Content-Lengthã‚’å‰Šé™¤
                if "Content-Length" in error_response.headers:
                    del error_response.headers["Content-Length"]
                return error_response

app.add_middleware(TimingMiddleware)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    force=True
)
logger = logging.getLogger(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """ã™ã¹ã¦ã®ä¾‹å¤–ã‚’å‡¦ç†ã—ã€502ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹"""
    import sys
    error_msg = f"âŒ Unhandled exception: {exc}"
    print(error_msg, flush=True)
    sys.stderr.write(error_msg + "\n")
    sys.stderr.flush()
    logger.error(error_msg, exc_info=True)
    try:
        return HTMLResponse(content=render_template("error.html", error_message=f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(exc)}"), status_code=500)
    except Exception as render_error:
        return HTMLResponse(content=f"<h1>ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ</h1><p>{str(exc)}</p><p><a href='/'>ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã«æˆ»ã‚‹</a></p>", status_code=500)

# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¨­å®š
jinja_env = Environment(loader=FileSystemLoader("templates"))

def render_template(template_name: str, **kwargs):
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    template = jinja_env.get_template(template_name)
    return template.render(**kwargs)

# èµ·å‹•æ™‚ã«å¿…ãšãƒ­ã‚°ã‚’å‡ºåŠ›
print("=" * 60, flush=True)
print("ğŸš€ Application starting (FastAPI)...", flush=True)
print(f"ğŸ“ VERB_CSV_PATH will be: {VERB_CSV_PATH}", flush=True)
print(f"ğŸ“ ADJECTIVE_CSV_PATH will be: {ADJECTIVE_CSV_PATH}", flush=True)
print("=" * 60, flush=True)

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ã®ãƒ­ãƒƒã‚¯
_cache_lock = Lock()
_cache_data = None
_cache_timestamp = 0
_cache_loading = False
CACHE_TTL = 600
CACHE_REFRESH_THRESHOLD = 540

def load_csv_data(csv_path):
    """CSVãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼ˆé«˜é€Ÿï¼‰"""
    try:
        msg = f"ğŸš€ Loading CSV from local file: {csv_path}"
        print(msg, flush=True)
        logger.info(msg)
        
        if not os.path.exists(csv_path):
            error_msg = f"CSV file not found: {csv_path}"
            print(f"âŒ {error_msg}", flush=True)
            logger.error(f"âŒ {error_msg}")
            raise FileNotFoundError(error_msg)
        
        file_size = os.path.getsize(csv_path)
        size_msg = f"ğŸ“Š CSV file size: {file_size:,} bytes ({file_size/1024:.2f} KB)"
        print(size_msg, flush=True)
        logger.info(size_msg)
        
        start_time = time.time()
        
        encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932', 'latin-1']
        df = None
        
        for encoding in encodings:
            try:
                encoding_msg = f"Trying encoding: {encoding}"
                print(encoding_msg, flush=True)
                logger.info(encoding_msg)
                df = pd.read_csv(csv_path, encoding=encoding)
                success_msg = f"âœ… CSV loaded successfully with encoding: {encoding}"
                print(success_msg, flush=True)
                logger.info(success_msg)
                break
            except UnicodeDecodeError:
                logger.debug(f"UnicodeDecodeError with encoding {encoding}, trying next...")
                continue
            except Exception as e:
                warning_msg = f"Failed to load with encoding {encoding}: {e}"
                print(warning_msg, flush=True)
                logger.warning(warning_msg)
                continue
        
        if df is None:
            error_msg = f"Failed to load CSV with any encoding. Tried: {encodings}"
            print(f"âŒ {error_msg}", flush=True)
            logger.error(f"âŒ {error_msg}")
            raise ValueError(error_msg)
        
        elapsed = time.time() - start_time
        shape_msg = f"âœ… CSV loaded in {elapsed:.3f}s, shape: {df.shape} (rows: {df.shape[0]}, cols: {df.shape[1]})"
        print(shape_msg, flush=True)
        logger.info(shape_msg)
        return df
    except FileNotFoundError as e:
        error_msg = f"âŒ CSV file not found: {csv_path}"
        print(error_msg, flush=True)
        logger.error(error_msg)
        logger.error(f"Current working directory: {os.getcwd()}")
        logger.error(f"Files in /app: {os.listdir('/app') if os.path.exists('/app') else 'N/A'}")
        raise
    except Exception as e:
        error_msg = f"âŒ Error loading CSV: {e}"
        print(error_msg, flush=True)
        logger.error(error_msg, exc_info=True)
        raise

def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆverb.csvã¨adjective.csvã®ä¸¡æ–¹ï¼‰"""
    all_chunks = []
    
    # verb.csvã‚’èª­ã¿è¾¼ã‚€
    if os.path.exists(VERB_CSV_PATH):
        check_msg = f"ğŸ” Checking for verb CSV file at: {VERB_CSV_PATH}"
        print(check_msg, flush=True)
        logger.info(check_msg)
        found_msg = f"âœ… Verb CSV file found! Using local CSV file - {VERB_CSV_PATH}"
        print(found_msg, flush=True)
        logger.info(found_msg)
        verb_df = load_csv_data(VERB_CSV_PATH)
        verb_chunks = split_data_into_chunks(verb_df, source='verb')
        all_chunks.extend(verb_chunks)
    else:
        warning_msg = f"âš ï¸ Verb CSV file NOT found at {VERB_CSV_PATH}. Skipping."
        print(warning_msg, flush=True)
        logger.warning(warning_msg)
    
    # adjective.csvã‚’èª­ã¿è¾¼ã‚€
    if os.path.exists(ADJECTIVE_CSV_PATH):
        check_msg = f"ğŸ” Checking for adjective CSV file at: {ADJECTIVE_CSV_PATH}"
        print(check_msg, flush=True)
        logger.info(check_msg)
        found_msg = f"âœ… Adjective CSV file found! Using local CSV file - {ADJECTIVE_CSV_PATH}"
        print(found_msg, flush=True)
        logger.info(found_msg)
        adjective_df = load_csv_data(ADJECTIVE_CSV_PATH)
        adjective_chunks = split_data_into_chunks(adjective_df, source='adjective')
        all_chunks.extend(adjective_chunks)
    else:
        warning_msg = f"âš ï¸ Adjective CSV file NOT found at {ADJECTIVE_CSV_PATH}. Skipping."
        print(warning_msg, flush=True)
        logger.warning(warning_msg)
    
    if len(all_chunks) == 0:
        error_msg = f"âŒ No CSV files found. Checked: {VERB_CSV_PATH}, {ADJECTIVE_CSV_PATH}"
        print(error_msg, flush=True)
        logger.error(error_msg)
        raise FileNotFoundError(error_msg)
    
    return all_chunks

def split_data_into_chunks(df, source='verb'):
    """ãƒ‡ãƒ¼ã‚¿ã‚’4è¡Œã”ã¨ã®å¡Šã«åˆ†å‰²ã—ã€å„å¡Šã®æƒ…å ±ã‚’è¿”ã™
    
    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        source: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼ˆ'verb'ã¾ãŸã¯'adjective'ï¼‰
    """
    chunks = []
    start_idx = 0
    while start_idx < len(df):
        end_idx = start_idx + 4
        if end_idx > len(df):
            end_idx = len(df)
        
        chunk_df = df.iloc[start_idx:end_idx].copy()
        
        if len(chunk_df) > 0:
            title = str(chunk_df.iloc[0, 0]).strip()
            # Båˆ—ï¼ˆ2åˆ—ç›®ï¼‰ã®å€¤ã‚’å–å¾—ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            subtitle = ""
            if len(chunk_df.columns) > 1:
                subtitle_value = chunk_df.iloc[0, 1]
                if pd.notna(subtitle_value):
                    subtitle = str(subtitle_value).strip()
            # ã‚½ãƒ¼ã‚¹ã‚’è€ƒæ…®ã—ãŸã‚¹ãƒ©ãƒƒã‚°ç”Ÿæˆï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
            base_slug = re.sub(r'[^\w\s-]', '', title.lower())
            base_slug = re.sub(r'[-\s]+', '-', base_slug)
            base_slug = base_slug.strip('-')
            # ã‚½ãƒ¼ã‚¹ã‚’ã‚¹ãƒ©ãƒƒã‚°ã«å«ã‚ã‚‹ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
            slug = f"{base_slug}-{source}" if source else base_slug
            
            chunks.append({
                'title': title,
                'subtitle': subtitle,  # Båˆ—ã®å€¤
                'slug': slug,
                'source': source,  # 'verb'ã¾ãŸã¯'adjective'
                'data': chunk_df,
                'columns': df.columns.tolist()
            })
        
        start_idx = end_idx
    
    return chunks

def get_all_chunks():
    """ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãã€Stale-While-Revalidateï¼‰"""
    global _cache_data, _cache_timestamp, _cache_loading
    
    current_time = time.time()
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã€ã™ãã«è¿”ã™
    with _cache_lock:
        if _cache_data is not None:
            cache_age = current_time - _cache_timestamp
            if cache_age < CACHE_TTL:
                return _cache_data
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤ã„ãŒã€ã¾ã æœ‰åŠ¹ãªå ´åˆï¼ˆStale-While-Revalidateï¼‰
            if cache_age < CACHE_TTL * 2:
                # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§æ›´æ–°ã‚’é–‹å§‹ï¼ˆæ—¢ã«æ›´æ–°ä¸­ã§ãªã„å ´åˆï¼‰
                if not _cache_loading:
                    _cache_loading = True
                    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§æ›´æ–°ï¼ˆãƒ­ãƒƒã‚¯ã‚’è§£æ”¾ã—ã¦ã‹ã‚‰ï¼‰
                    threading.Thread(target=_refresh_cache, daemon=True).start()
                # å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¿”ã™
                return _cache_data
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„ã€ã¾ãŸã¯å®Œå…¨ã«ç„¡åŠ¹ãªå ´åˆã€åŒæœŸçš„ã«æ›´æ–°
    return _refresh_cache()

def _refresh_cache():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°"""
    global _cache_data, _cache_timestamp, _cache_loading
    
    try:
        chunks = load_data()  # load_data()ã¯æ—¢ã«ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
        
        with _cache_lock:
            _cache_data = chunks
            _cache_timestamp = time.time()
            _cache_loading = False
        
        logger.info(f"âœ… Cache refreshed: {len(chunks)} chunks")
        return chunks
    except Exception as e:
        with _cache_lock:
            _cache_loading = False
        logger.error(f"âŒ Cache refresh failed: {e}", exc_info=True)
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Œã°ãã‚Œã‚’è¿”ã™
        if _cache_data is not None:
            logger.warning(f"Using stale cache due to error: {e}")
            return _cache_data
        raise

# åˆæœŸåŒ–ãƒ•ãƒ©ã‚°
_initialized = False
_init_lock = Lock()

def ensure_initialized():
    """æœ€åˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã«åˆæœŸåŒ–ã‚’å®Ÿè¡Œ"""
    global _initialized
    
    if _initialized:
        return
    
    init_start_time = time.time()
    max_wait_time = 5.0
    
    while not _initialized and (time.time() - init_start_time) < max_wait_time:
        with _init_lock:
            if _initialized:
                return
            if _cache_loading and _cache_data is not None:
                _initialized = True
                return
        time.sleep(0.1)
    
    with _init_lock:
        if _initialized:
            return
        
        try:
            import sys
            sys.stdout.write("=" * 60 + "\n")
            sys.stdout.write("ğŸš€ Starting application initialization...\n")
            sys.stdout.write(f"ğŸ“ VERB_CSV_PATH: {VERB_CSV_PATH}\n")
            sys.stdout.write(f"ğŸ“ ADJECTIVE_CSV_PATH: {ADJECTIVE_CSV_PATH}\n")
            sys.stdout.write(f"ğŸ“‚ Current working directory: {os.getcwd()}\n")
            sys.stdout.flush()
            
            logger.info("=" * 60)
            logger.info("ğŸš€ Starting application initialization...")
            logger.info(f"ğŸ“ VERB_CSV_PATH: {VERB_CSV_PATH}")
            logger.info(f"ğŸ“ ADJECTIVE_CSV_PATH: {ADJECTIVE_CSV_PATH}")
            logger.info(f"ğŸ“‚ Current working directory: {os.getcwd()}")
            
            found_files = []
            if os.path.exists(VERB_CSV_PATH):
                file_size = os.path.getsize(VERB_CSV_PATH)
                msg = f"âœ… Verb CSV file found! Size: {file_size:,} bytes ({file_size/1024:.2f} KB)"
                sys.stdout.write(msg + "\n")
                sys.stdout.flush()
                logger.info(msg)
                found_files.append(VERB_CSV_PATH)
            else:
                warning_msg = f"âš ï¸ Verb CSV file NOT found at {VERB_CSV_PATH}"
                sys.stdout.write(warning_msg + "\n")
                sys.stdout.flush()
                logger.warning(warning_msg)
            
            if os.path.exists(ADJECTIVE_CSV_PATH):
                file_size = os.path.getsize(ADJECTIVE_CSV_PATH)
                msg = f"âœ… Adjective CSV file found! Size: {file_size:,} bytes ({file_size/1024:.2f} KB)"
                sys.stdout.write(msg + "\n")
                sys.stdout.flush()
                logger.info(msg)
                found_files.append(ADJECTIVE_CSV_PATH)
            else:
                warning_msg = f"âš ï¸ Adjective CSV file NOT found at {ADJECTIVE_CSV_PATH}"
                sys.stdout.write(warning_msg + "\n")
                sys.stdout.flush()
                logger.warning(warning_msg)
            
            if len(found_files) == 0:
                error_msg = f"âŒ No CSV files found. Checked: {VERB_CSV_PATH}, {ADJECTIVE_CSV_PATH}"
                sys.stderr.write(error_msg + "\n")
                sys.stderr.flush()
                logger.error(error_msg)
                if os.path.exists('/app'):
                    sys.stdout.write("ğŸ“‹ Files in /app directory:\n")
                    sys.stdout.flush()
                    logger.info("ğŸ“‹ Files in /app directory:")
                    for f in os.listdir('/app'):
                        full_path = os.path.join('/app', f)
                        if os.path.isfile(full_path):
                            size = os.path.getsize(full_path)
                            file_info = f"   - {f} ({size:,} bytes)"
                            sys.stdout.write(file_info + "\n")
                            sys.stdout.flush()
                            logger.info(file_info)
                        else:
                            dir_info = f"   - {f}/ (directory)"
                            sys.stdout.write(dir_info + "\n")
                            sys.stdout.flush()
                            logger.info(dir_info)
                raise FileNotFoundError(error_msg)
            
            sys.stdout.write("ğŸ“¦ Preloading cache on startup...\n")
            sys.stdout.flush()
            logger.info("ğŸ“¦ Preloading cache on startup...")
            get_all_chunks()
            sys.stdout.write("âœ… Cache preloaded successfully\n")
            sys.stdout.write("=" * 60 + "\n")
            sys.stdout.flush()
            logger.info("âœ… Cache preloaded successfully")
            logger.info("=" * 60)
            
            _initialized = True
        except Exception as e:
            error_msg = f"âŒ Failed to preload cache: {e}"
            import sys
            sys.stderr.write(error_msg + "\n")
            sys.stderr.flush()
            logger.error(error_msg, exc_info=True)
            raise

@app.get("/", response_class=HTMLResponse)
@app.head("/")
async def index(request: Request, q: str = ""):
    """ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ï¼šæ¤œç´¢çª“ã®ã¿"""
    import sys
    request_start = time.time()
    request_id = f"{request.client.host}:{request.client.port}-{int(request_start * 1000)}"
    is_head = request.method == "HEAD"
    
    # HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å ´åˆã¯ã€ã™ãã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆåˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯ã‚‚ä¸è¦ï¼‰
    if is_head:
        response = HTMLResponse(content="", status_code=200)
        response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
        response.headers["CF-Cache-Status"] = "DYNAMIC"
        return response
    
    logger.info(f"ğŸ“¥ Request {request_id}: {request.method} /?q={q}")
    try:
        ensure_initialized()
        
        query = q.strip()
        results = []
        
        if query:
            msg = f"ğŸ” Search request received: '{query}'"
            print(msg, flush=True)
            logger.info(msg)
            
            try:
                start_time = time.time()
                chunks = get_all_chunks()
                load_time = time.time() - start_time
                msg = f"ğŸ“¦ Chunks loaded in {load_time:.3f}s (total: {len(chunks)} chunks)"
                print(msg, flush=True)
                logger.info(msg)
                
                query_lower = query.lower()
                search_start = time.time()
                
                chunk_count = 0
                for chunk in chunks:
                    chunk_count += 1
                    try:
                        if query_lower in chunk['title'].lower():
                            results.append(chunk)
                            continue
                        
                        found = False
                        for col in chunk['data'].columns:
                            if found:
                                break
                            col_values = chunk['data'][col].astype(str).str.lower()
                            if col_values.str.contains(query_lower, na=False).any():
                                results.append(chunk)
                                found = True
                                break
                    except Exception as chunk_error:
                        logger.warning(f"Error processing chunk {chunk_count}: {chunk_error}")
                        continue
                
                search_time = time.time() - search_start
                msg = f"âœ… Search completed in {search_time:.3f}s, found {len(results)} results (searched {chunk_count} chunks)"
                print(msg, flush=True)
                logger.info(msg)
            except Exception as search_error:
                error_msg = f"âŒ Search error: {search_error}"
                print(error_msg, flush=True)
                sys.stderr.write(error_msg + "\n")
                sys.stderr.flush()
                logger.error(error_msg, exc_info=True)
                results = []
        
        total_time = time.time() - request_start
        logger.info(f"âœ… Request {request_id} completed in {total_time:.3f}s")
        if total_time > 1.0:
            msg = f"âš ï¸ Slow request {request_id}: {total_time:.3f}s"
            print(msg, flush=True)
            logger.warning(msg)
        
        response = HTMLResponse(content=render_template("index.html", query=query, results=results))
        logger.info(f"ğŸ“¤ Request {request_id}: Sending response (status: 200)")
        return response
    except Exception as e:
        error_msg = f"âŒ Error in index: {e}"
        print(error_msg, flush=True)
        sys.stderr.write(error_msg + "\n")
        sys.stderr.flush()
        logger.error(error_msg, exc_info=True)
        try:
            return HTMLResponse(content=render_template("error.html", error_message=f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"), status_code=500)
        except Exception as render_error:
            return HTMLResponse(content=f"<h1>ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ</h1><p>{str(e)}</p>", status_code=500)

@app.get("/health")
@app.head("/health")
async def health(request: Request):
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    # HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å ´åˆã¯ã€ã™ãã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆåˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯ã‚‚ä¸è¦ï¼‰
    if request.method == "HEAD":
        response = HTMLResponse(content="", status_code=200)
        response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
        response.headers["CF-Cache-Status"] = "DYNAMIC"
        return response
    
    try:
        ensure_initialized()
        
        with _cache_lock:
            if _cache_data is not None:
                cache_age = time.time() - _cache_timestamp
                response_text = f"OK (cache age: {int(cache_age)}s)"
            else:
                response_text = "OK (cache not ready)"
        
        return response_text
    except Exception as e:
        error_msg = f"Health check error: {e}"
        print(error_msg, flush=True)
        logger.error(error_msg, exc_info=True)
        raise HTTPException(status_code=503, detail="ERROR")

@app.get("/{slug}", response_class=HTMLResponse)
@app.head("/{slug}")
async def page_detail(request: Request, slug: str):
    """å€‹åˆ¥ãƒšãƒ¼ã‚¸ï¼šå„å¡Šã®è©³ç´°è¡¨ç¤º"""
    import sys
    request_start = time.time()
    request_id = f"{request.client.host}:{request.client.port}-{int(request_start * 1000)}"
    is_head = request.method == "HEAD"
    
    # HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å ´åˆã¯ã€è»½é‡ãªãƒã‚§ãƒƒã‚¯ã®ã¿ï¼ˆåˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯ã¯ä¸è¦ï¼‰
    if is_head:
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ã®ã¿ãƒã‚§ãƒƒã‚¯
            with _cache_lock:
                if _cache_data is None:
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã¯ã€ã™ãã«200ã‚’è¿”ã™ï¼ˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                    response = HTMLResponse(content="", status_code=200)
                    response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
                    response.headers["CF-Cache-Status"] = "DYNAMIC"
                    return response
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚‹å ´åˆã¯ã€è»½é‡ãªå­˜åœ¨ãƒã‚§ãƒƒã‚¯
            chunks = get_all_chunks()
            chunk = None
            for c in chunks:
                if c['slug'] == slug:
                    chunk = c
                    break
            if not chunk:
                response = HTMLResponse(content="", status_code=404)
                response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
                response.headers["CF-Cache-Status"] = "DYNAMIC"
                return response
            response = HTMLResponse(content="", status_code=200)
            response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            response.headers["CF-Cache-Status"] = "DYNAMIC"
            return response
        except Exception:
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã§ã‚‚ã€200ã‚’è¿”ã™ï¼ˆ502ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
            response = HTMLResponse(content="", status_code=200)
            response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            response.headers["CF-Cache-Status"] = "DYNAMIC"
            return response
    
    logger.info(f"ğŸ“¥ Request {request_id}: {request.method} /{slug}")
    try:
        msg = f"ğŸ“„ Page detail request: {slug}"
        print(msg, flush=True)
        logger.info(msg)
        
        ensure_initialized()
        
        start_time = time.time()
        chunks = get_all_chunks()
        load_time = time.time() - start_time
        msg = f"ğŸ“¦ Chunks loaded in {load_time:.3f}s (total: {len(chunks)} chunks)"
        print(msg, flush=True)
        logger.info(msg)
        
        chunk = None
        search_start = time.time()
        for c in chunks:
            if c['slug'] == slug:
                chunk = c
                break
        search_time = time.time() - search_start
        
        if not chunk:
            msg = f"âŒ Page not found: {slug} (searched {len(chunks)} chunks in {search_time:.3f}s)"
            print(msg, flush=True)
            logger.warning(msg)
            return HTMLResponse(content=render_template("error.html", error_message=f"ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {slug}"), status_code=404)
        
        msg = f"âœ… Found chunk: {chunk['title']} (search took {search_time:.3f}s)"
        print(msg, flush=True)
        logger.info(msg)
        
        try:
            if len(chunk['data'].columns) > 1:
                display_df = chunk['data'].iloc[:, 1:].copy()
            else:
                display_df = chunk['data'].copy()
            
            display_df = display_df.fillna('')
            
            # æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ï¼ˆã‚»ãƒ«å†…ã®æ–‡å­—ã¯çµ¶å¯¾ã«æ”¹è¡Œã—ãªã„ï¼‰
            for col in display_df.columns:
                # ã™ã¹ã¦ã®ç¨®é¡ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤
                display_df[col] = display_df[col].astype(str).str.replace('\n', ' ', regex=False).str.replace('\r', ' ', regex=False).str.replace('\r\n', ' ', regex=False)
                # é€£ç¶šã™ã‚‹ã‚¹ãƒšãƒ¼ã‚¹ã‚’1ã¤ã«ã¾ã¨ã‚ã‚‹
                display_df[col] = display_df[col].str.replace(r'\s+', ' ', regex=True).str.strip()
            
            table_start = time.time()
            table_html = display_df.to_html(
                classes="table",
                index=False,
                border=0,
                escape=False,  # HTMLã‚¿ã‚°ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ãªã„
            )
            # ç”Ÿæˆã•ã‚ŒãŸHTMLã‹ã‚‰ã‚‚æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã¨<br>ã‚¿ã‚°ã‚’å‰Šé™¤ï¼ˆå‹•è©ãƒ»å½¢å®¹è©å…±é€šã®å‡¦ç†ï¼‰
            # <td>ã¨</td>ã®é–“ã®æ”¹è¡Œã‚’å‰Šé™¤ï¼ˆã‚»ãƒ«å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’1è¡Œã«ä¿ã¤ï¼‰
            def clean_cell_content(match):
                """ã‚»ãƒ«å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰æ”¹è¡Œã‚’å®Œå…¨ã«å‰Šé™¤"""
                tag_start = match.group(1)
                content = match.group(2)
                tag_end = match.group(3)
                # ã™ã¹ã¦ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã€<br>ã‚¿ã‚°ã€é€£ç¶šã™ã‚‹ã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤
                cleaned = re.sub(r'<br\s*/?>', ' ', content, flags=re.IGNORECASE)
                cleaned = cleaned.replace('\n', ' ').replace('\r', '').replace('\t', ' ')
                cleaned = re.sub(r'\s+', ' ', cleaned).strip()
                return tag_start + cleaned + tag_end
            
            table_html = re.sub(r'(<td[^>]*>)(.*?)(</td>)', clean_cell_content, table_html, flags=re.DOTALL)
            # <th>ã¨</th>ã®é–“ã®æ”¹è¡Œã‚‚å‰Šé™¤
            table_html = re.sub(r'(<th[^>]*>)(.*?)(</th>)', clean_cell_content, table_html, flags=re.DOTALL)
            # HTMLå…¨ä½“ã®æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ï¼ˆãŸã ã—ã€ã‚¿ã‚°é–“ã®æ§‹é€ ã¯ä¿æŒï¼‰
            table_html = re.sub(r'\n\s*', ' ', table_html)
            table_html = re.sub(r'\r\s*', ' ', table_html)
            table_html = re.sub(r'\s+', ' ', table_html)
            # ã‚¿ã‚°é–“ã®ä¸è¦ãªã‚¹ãƒšãƒ¼ã‚¹ã‚’æ•´ç†
            table_html = re.sub(r'>\s+<', '><', table_html)
            table_elapsed = time.time() - table_start
            logger.info(f"ğŸ“Š Table HTML generated in {table_elapsed:.3f}s")
            
            total_elapsed = time.time() - request_start
            logger.info(f"âœ… Request {request_id} (page_detail) completed in {total_elapsed:.3f}s")
            if total_elapsed > 1.0:
                logger.warning(f"âš ï¸ Slow page detail {request_id}: {total_elapsed:.3f}s for slug '{slug}'")
            
            response = HTMLResponse(content=render_template("detail.html", title=chunk['title'], table_html=table_html))
            logger.info(f"ğŸ“¤ Request {request_id}: Sending response (status: 200)")
            return response
        except Exception as table_error:
            error_msg = f"âŒ Error generating table: {table_error}"
            print(error_msg, flush=True)
            logger.error(error_msg, exc_info=True)
            return HTMLResponse(content=render_template("error.html", error_message=f"ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(table_error)}"), status_code=500)
    except Exception as e:
        error_msg = f"âŒ Error in page_detail: {e}"
        print(error_msg, flush=True)
        sys.stderr.write(error_msg + "\n")
        sys.stderr.flush()
        logger.error(error_msg, exc_info=True)
        try:
            return HTMLResponse(content=render_template("error.html", error_message=f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"), status_code=500)
        except Exception as render_error:
            return HTMLResponse(content=f"<h1>ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ</h1><p>{str(e)}</p>", status_code=500)

# èµ·å‹•æ™‚ã®åˆæœŸåŒ–
try:
    import sys
    if not _initialized:
        try:
            print("ğŸš€ Attempting to preload application at startup...", flush=True)
            ensure_initialized()
            print("âœ… Application preloaded successfully at startup", flush=True)
        except Exception as preload_error:
            print(f"âš ï¸ Preload failed (will initialize on first request): {preload_error}", flush=True)
            sys.stderr.write(f"âš ï¸ Preload failed (will initialize on first request): {preload_error}\n")
            sys.stderr.flush()
except Exception as e:
    pass

